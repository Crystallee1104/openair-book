[
["index.html", "openair Section 1 Prerequisites", " openair David Carslaw 2020-07-20 Section 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],
["intro.html", "Section 2 Introduction", " Section 2 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter ??. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). See (Carslaw et al. 2006) References "],
["sec-importAURN.html", "Section 3 Accessing UK Air Quality Data 3.1 Accessing data 3.2 Site Meta Data 3.3 Plot Sites on a Map", " Section 3 Accessing UK Air Quality Data The UK has a surprisingly large amount of air quality data that is publicly accessible. The main UK AURN archive and regional (England, Scotland, Wales and Northern Ireland) together with Imperial College London’s London Air Quality Network (LAQN) are important and large databases of information that allow free public access. Storing and managing data in this way has many advantages including consistent data format, and underlying high quality methods to process and store the data. 3.1 Accessing data openair has a family of functions that provide users with extensive access to UK air quality data. Ricardo Energy &amp; Environment have provided .RData files (R workspaces) for several important air quality networks in the UK. These files are updated on a daily basis. This approach requires a link to the Internet to work. The networks include: importAURN For importing data from the UK national network called Automatic Urban and Rural Network}. This is the main UK network. importSAQN For accessing data from Air Quality Scotland network. importWAQN For accessing data from the Air Quality Wales network. importAQE For accessing data from the Air Quality England network of sites. importNI For accessing data from the Northern Ireland network of sites. importEurope A simplified version of a function to give basic access to hourly European data based on Stuart Grange’s package — see https://github.com/skgrange/saqgetr. The openair function has a similar approach to other openair import functions i.e. requires a site code(s) and year(s) to be supplied. importKCL For accessing data from the sites operated by King’s College London, primarily including the The London Air Quality Network. Many users download hourly data from the air quality archive at http://www.airquality.co.uk. Most commonly, the data are emailed to the user as .csv files and have a fixed format as shown below. This is a useful facility but does have some limitations and frustrations, many of which have been overcome using a new way of storing and downloading the data described below. There are several advantages over the web portal approach where .csv files are downloaded. First, it is quick to select a range of sites, pollutants and periods (see examples below). Second, storing the data as .RData objects is very efficient as they are about four times smaller than .csv files (which are already small) — which means the data downloads quickly and saves bandwidth. Third, the function completely avoids any need for data manipulation or setting time formats, time zones etc. Finally, it is easy to import many years of data. The final point makes it possible to download several long time series in one go. The site codes and pollutant names can be upper or lower case. The function will issue a warning when data less than six months old is downloaded, which may not be ratified. Type ?importAURN for a full listing of sites and their codes. Some examples of usage are shown below. First load the packages we need. library(openair) library(tidyverse) ## import all pollutants from Marylebone Rd from 1990:2009 mary &lt;- importAURN(site = &quot;my1&quot;, year = 2000:2009) ## import nox, no2, o3 from Marylebone Road and Nottingham Centre for 2000 thedata &lt;- importAURN(site = c(&quot;my1&quot;, &quot;nott&quot;), year = 2000, pollutant = c(&quot;nox&quot;, &quot;no2&quot;, &quot;o3&quot;)) ## import over 20 years of Mace Head O3 data! o3 &lt;- importAURN(site = &quot;mh&quot;, year = 1987:2009) ## import hydrocarbon data from Marylebone Road hc &lt;- importAURN(site = &quot;my1&quot;, year = 2008, hc = TRUE) By default, the function returns data where each pollutant is in a separate column. However, it is possible to return the data in a tidy format (column for pollutant name, column for value) by using the option to_narrow: my1 &lt;- importAURN(&quot;my1&quot;, year = 2018, to_narrow = TRUE) 3.2 Site Meta Data Users can access the details of air pollution monitoring sites using the importMeta function. The user only needs to provide the network name and (optionally) whether all data should be returned. By default only site type, latitude and longitude are returned. library(tidyverse) aurn_meta &lt;- importMeta(source = &quot;aurn&quot;) aurn_meta ## # A tibble: 273 x 5 ## site code latitude longitude site_type ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Aberdeen ABD 57.2 -2.09 Urban Background ## 2 Aberdeen Union Street Roadside ABD7 57.1 -2.11 Urban Traffic ## 3 Aberdeen Wellington Road ABD8 57.1 -2.09 Urban Traffic ## 4 Armagh Roadside ARM6 54.4 -6.65 Urban Traffic ## 5 Aston Hill AH 52.5 -3.03 Rural Background ## 6 Auchencorth Moss ACTH 55.8 -3.24 Rural Background ## 7 Ballymena Antrim Road BAAR 54.9 -6.27 Urban Traffic ## 8 Ballymena Ballykeel BALM 54.9 -6.25 Urban Background ## 9 Barnsley BARN 53.6 -1.48 Urban Background ## 10 Barnsley 12 BAR2 53.6 -1.49 Urban Background ## # … with 263 more rows Or return much more detailed data: aurn_meta &lt;- importMeta(source = &quot;aurn&quot;, all = TRUE) aurn_meta And to include basic meta data when importing air pollution data: kc1 &lt;- importAURN(site = &quot;kc1&quot;, year = 2018, meta = TRUE) glimpse(kc1) ## Rows: 8,760 ## Columns: 17 ## $ site &lt;chr&gt; &quot;London N. Kensington&quot;, &quot;London N. Kensington&quot;, &quot;London N. … ## $ code &lt;chr&gt; &quot;KC1&quot;, &quot;KC1&quot;, &quot;KC1&quot;, &quot;KC1&quot;, &quot;KC1&quot;, &quot;KC1&quot;, &quot;KC1&quot;, &quot;KC1&quot;, &quot;KC… ## $ date &lt;dttm&gt; 2018-01-01 00:00:00, 2018-01-01 01:00:00, 2018-01-01 02:00… ## $ co &lt;dbl&gt; 0.114872, 0.111043, 0.112000, 0.100512, 0.091897, 0.100512,… ## $ nox &lt;dbl&gt; 8.32519, 8.89934, 9.41967, 9.36584, 7.21277, 7.64339, 10.17… ## $ no2 &lt;dbl&gt; 8.11153, 8.54325, 8.99235, 8.93852, 6.94570, 7.26948, 10.01… ## $ no &lt;dbl&gt; 0.13935, 0.23224, 0.27869, 0.27869, 0.17418, 0.24386, 0.104… ## $ o3 &lt;dbl&gt; 70.98040, 67.52118, 69.69982, 70.49810, 71.74542, 70.49810,… ## $ so2 &lt;dbl&gt; NA, 2.40953, 2.49812, 2.12606, 2.39181, 2.28551, 2.23236, 2… ## $ pm10 &lt;dbl&gt; 12.425, 7.375, 5.625, 3.200, 3.875, 5.050, 9.400, 12.400, 1… ## $ pm2.5 &lt;dbl&gt; 8.892, 4.363, 3.137, 1.792, 2.146, 2.618, 4.575, 6.109, 7.0… ## $ ws &lt;dbl&gt; 5.5, 5.0, 4.8, 4.8, 5.3, 5.3, 4.4, 3.0, 2.6, 1.6, 1.6, 1.1,… ## $ wd &lt;dbl&gt; 263.3, 256.4, 251.0, 246.8, 248.4, 248.0, 245.8, 239.5, 232… ## $ air_temp &lt;dbl&gt; 5.5, 5.1, 4.9, 4.7, 4.9, 5.0, 5.0, 4.6, 4.2, 3.7, 5.4, 5.7,… ## $ latitude &lt;dbl&gt; 51.52105, 51.52105, 51.52105, 51.52105, 51.52105, 51.52105,… ## $ longitude &lt;dbl&gt; -0.213492, -0.213492, -0.213492, -0.213492, -0.213492, -0.2… ## $ site_type &lt;chr&gt; &quot;Urban Background&quot;, &quot;Urban Background&quot;, &quot;Urban Background&quot;,… 3.3 Plot Sites on a Map The example below uses sites on the AURN that measure NO2, but can easily be extended to the other data sources. aurn_detailed &lt;- importMeta(source = &quot;aurn&quot;, all = TRUE) no2_sites &lt;- filter( aurn_detailed, variable == &quot;NO2&quot;, site_type == &quot;Urban Traffic&quot; ) nrow(no2_sites) ## [1] 89 In the example below the unique sites are selected from aurn_detailed because the site repeats the number of pollutants that are measured. Information is also collected for the map popups and then the map is plotted. library(leaflet) aurn_unique &lt;- distinct(aurn_detailed, site, .keep_all = TRUE) # information for map markers content &lt;- paste( paste( aurn_unique$site, paste(&quot;Code:&quot;, aurn_unique$code), paste(&quot;Start:&quot;, aurn_unique$start_date), paste(&quot;End:&quot;, aurn_unique$end_date), paste(&quot;Site Type:&quot;, aurn_unique$site_type), sep = &quot;&lt;br/&gt;&quot; ) ) # plot map leaflet(aurn_unique) %&gt;% addTiles() %&gt;% addMarkers(~ longitude, ~ latitude, popup = content, clusterOptions = markerClusterOptions()) "],
["sec-windRose.html", "Section 4 Wind and Pollution Roses 4.1 Example of use 4.2 Comparing two meteorological data sets", " Section 4 Wind and Pollution Roses The wind rose is a very useful way of summarising meteorological data. It is particularly useful for showing how wind speed and wind direction conditions vary by year. The windRose function can plot wind roses in a variety of ways: summarising all available wind speed and wind direction data, plotting individual wind roses by year, and also by month. The latter is useful for considering how meteorological conditions vary by season. Data are summarised by direction, typically by 45 or 30\\(^\\circ\\) and by different wind speed categories. Typically, wind speeds are represented by different width ‘paddles’. The plots show the proportion (here represented as a percentage) of time that the wind is from a certain angle and wind speed range. The windRose function also calculates the percentage of ‘calms’ i.e. when the wind speed is zero. UK Met Office data assigns these periods to 0 degrees wind direction with valid northerly winds being assigned to 360\\(^\\circ\\). The windRose function will also correct for bias when wind directions are rounded to the nearest 10 degrees but are displayed at angles that 10 degrees is not exactly divisible into e.g. 22.5\\(^\\circ\\). When such data are binned, some angles i.e. N, E, S, W will comprise three intervals whereas others will comprise two, which can lead to significant bias. This issue and its solution is discussed by Droppo and Napier (2008) and Applequist (2012).1 openair uses a simple method to correct for the bias by globally rescaling the count in each wind direction bin by the number of directions it represents relative to the average. Thus, the primary four directions are each reduced by a factor of 0.75 and the remaining 12 directions are multiplied by 1.125. 4.1 Example of use First we load the packages: library(openair) library(tidyverse) The function is very simply called as shown for Figure 4.1. windRose(mydata) Figure 4.1: Use of windRose function to plot wind speed/direction frequencies. Wind speeds are split into the intervals shown by the scale in each panel. The grey circles show the % frequencies. Figure 4.2 highlights some interesting differences between the years. In 2000, for example, there were numerous occasions when the wind was from the SSW and 2003 clearly had more occasions when the wind was easterly. It can also be useful to use type = \"month\" to get an idea of how wind speed and direction vary seasonally. windRose(mydata, type = &quot;year&quot;, layout = c(4, 2)) Figure 4.2: Use of windRose function to plot wind speed/direction frequencies by year. Wind speeds are split into the intervals shown by the scale in each panel. The grey circles show the 10 and 20% frequencies. The type option is very flexible in openair and can be used to quickly consider the dependencies between variables. Section ?? describes the basis of this option in openair plot. As an example, consider the question: what are the meteorological conditions that control high and low concentrations of PM10? By setting type = \"pm10\", openair will split the PM10 concentrations into four quantiles i.e. roughly equal numbers of points in each level. The plot will then show four different wind roses for each quantile level, although the default number of levels can be set by the user — see ?cutData for more details. Figure 4.3 shows the results of setting type = \"pm10\". For the lowest concentrations of PM10 the wind direction is dominated by northerly winds, and relatively low wind speeds. By contrast, the highest concentrations (plot furthest right) are dominated by relatively strong winds from the south-west. It is therefore very easy to obtain a good idea about the conditions that tend to lead to high (or low) concentrations of a pollutant. Furthermore, the type option is available in almost all openair functions. windRose(mydata, type = &quot;pm10&quot;, layout = c(4, 1)) Figure 4.3: Wind rose for four different levels of PM10 concentration. The levels are defined as the four quantiles of PM10 concentration and the ranges are shown on each of the plot labels. A comparison of the effect that bias has can be seen by plotting the following. Note the prominent frequencies for W, E and N in particular that are due to the bias issue discussed by Applequist (2012). ## no bias correction windRose(mydata, angle = 22.5, bias.corr = FALSE) ## bias correction (the default) windRose(mydata, angle = 22.5) pollutionRose is a variant of windRose that is useful for considering pollutant concentrations by wind direction, or more specifically the percentage time the concentration is in a particular range. This type of approach can be very informative for air pollutant species, as demonstrated by Ronald Henry and co-authors in Henry et al. (2009). You can produce similar pollution roses using the pollutionRose function in recent versions of openair, e.g. as in Figure 4.4: pollutionRose(mydata, pollutant = &quot;nox&quot;) Figure 4.4: NOx pollution rose produced using pollutionRose and default pollutionRose settings. pollutionRose is wrapper for windRose. It simply replaces the wind speed data series in the supplied data set with another variable using the argument pollutant before passing that on to windRose. It also modifies breaks to estimate a sensible set of break points for that pollutant and uses a slightly different set of default options (key to right, wedge style plot) but otherwise handles arguments just like the parent windRose function. While Figure 4.4 indicates that higher NOx concentrations are also associated with the SW, conditioning allows you to be much informative. For example, conditioning by SO2 (Figure 4.5 demonstrates that higher NOx concentrations are associated with the SW and much of the higher SO2 concentrations. However, it also highlights a notable NOx contribution from the E, most apparent at highest SO2 concentrations that is obscured in Figure 4.4 by a relatively high NOx background (Figure 4.5. pollutionRose(mydata, pollutant = &quot;nox&quot;, type = &quot;so2&quot;, layout = c(4, 1)) Figure 4.5: NOx pollution rose conditioned by SO2 concentration. pollutionRose can also usefully be used to show which wind directions dominate the overall concentrations. By supplying the option statistic = \"prop.mean\" (proportion contribution to the mean), a good idea can be gained as to which wind directions contribute most to overall concentrations, as well as providing information on the different concentration levels. A simple plot is shown in Figure 4.6, which clearly shows the dominance of south-westerly winds controlling the overall mean NOx concentrations at this site. Indeed, almost half the overall NOx concentration is contributed by two wind sectors to the south-west. The polarFreq function can also show this sort of information, but the pollution rose is more effective because both length and colour are used to show the contribution. These plots are very useful for understanding which wind directions control the overall mean concentrations. pollutionRose(mydata, pollutant = &quot;nox&quot;, statistic = &quot;prop.mean&quot;) Figure 4.6: Pollution rose showing which wind directions contribute most to overall mean concentrations. It is sometimes useful to more clearly understand the contributions from wind directions that have low frequencies. For example, for a pollution rose of SO2 there are few occurrences of easterly winds making it difficult to see how the concentration intervals are made up. Try: pollutionRose(mydata, pollutant = &quot;so2&quot;, seg = 1) However, each wind sector can be normalised to give a probability between 0 and 1 to help show the variation within each wind sector more clearly. An example is shown in Figure 4.7 where for easterly winds it is now clearer that a greater proportion of the time the concentration is made up of high SO2 concentrations. In this plot each wind sector is scaled between 0 and 1. Also shown with a black like is an indication of the wind direction frequency to remind us that winds from the east occur with a low frequency. pollutionRose(mydata, pollutant = &quot;so2&quot;, normalise = TRUE, seg = 1) Figure 4.7: SO2 pollution rose produced using pollutionRose normalised by each wind sector. 4.2 Comparing two meteorological data sets The pollutionRose function is also useful for comparing two meteorological data sets. In this case a ‘reference’ data set is compared with a second data set. There are many reasons for doing so e.g. to see how one site compares with another or for meteorological model evaluation (more on that in later sections). In this case, ws and wd are considered to the the reference data sets with which a second set of wind speed and wind directions are to be compared (ws2 and wd2). The first set of values is subtracted from the second and the differences compared. If for example, wd2 was biased positive compared with wd then pollutionRose will show the bias in polar coordinates. In its default use, wind direction bias is colour-coded to show negative bias in one colour and positive bias in another. Note that this plot is mostly aimed at showing wind direction biases. It does also show the wind speed bias but only if there is a wind direction bias also. However, in most practical situations the plot should show both wind speed and direction biases together. An example of a situation where no wind speed bias would be shown would be for westerly winds where there was absolutely no bias between two data sets in terms of westerly wind direction but there was a difference in wind speed. Users should be aware of this limitation. In the next example, some artificial wind direction data are generated by adding a positive bias of 30~degrees with some normally distributed scatter. Also, the wind speed data are given a positive bias. The results are shown in Figure 4.8. The Figure clearly shows the mean positive bias in wind direction i.e. the direction is displaced from north (no bias). The colour scale also shows the extent to which wind speeds are biased i.e. there is a higher proportion of positively biased wind speeds shown by the red colour compared with the negatively biased shown in blue. Also shown in Figure 4.8 is the mean wind speed and direction bias as numerical values. Note that the type option can be used in Figure 4.8 e.g. type = \"month\" to split the analysis in useful ways. This is useful if one wanted to see whether a site or the output from a model was biased for different periods. For example, type = \"daylight\" would show whether there are biases between nighttime and daytime conditions. ## $example of comparing 2 met sites ## first we will make some new ws/wd data with a postive bias mydata &lt;- mutate(mydata, ws2 = ws + 2 * rnorm(nrow(mydata)) + 1, wd2 = wd + 30 * rnorm(nrow(mydata)) + 30) ## need to correct negative wd id &lt;- which(mydata$wd2 &lt; 0) mydata$wd2[id] &lt;- mydata$wd2[id] + 360 ## results show postive bias in wd and ws pollutionRose(mydata, ws = &quot;ws&quot;, wd = &quot;wd&quot;, ws2 = &quot;ws2&quot;, wd2 = &quot;wd2&quot;, grid.line = 5) Figure 4.8: Pollution rose showing the difference between two meteorological data sets. The colours are used to show whether data tend to be positively or negatively biased with respect to the reference data set. An example of using user-supplied breaks is shown in Figure 4.9. In this case six intervals are chosen including one that spans -0.5 to +0.5 that is useful to show wind speeds that do not change. ## add some wd bias to some nighttime hours id &lt;- which(as.numeric(format(mydata$date, &quot;%H&quot;)) %in% c(23, 1, 2, 3, 4, 5)) mydata$wd2[id] &lt;- mydata$wd[id] + 30 * rnorm(length(id)) + 120 id &lt;- which(mydata$wd2 &lt; 0) mydata$wd2[id] &lt;- mydata$wd2[id] + 360 pollutionRose(mydata, ws = &quot;ws&quot;, wd = &quot;wd&quot;, ws2 = &quot;ws2&quot;, wd2 = &quot;wd2&quot;, breaks = c(-11, -2, -1, -0.5, 0.5, 1, 2, 11), cols = c(&quot;dodgerblue4&quot;, &quot;white&quot;, &quot;firebrick&quot;), grid.line = 5, type = &quot;daylight&quot;) Figure 4.9: Pollution rose showing the difference between two meteorological data sets. The colours are used to show whether data tend to be positively or negatively biased with respect to the reference data set. In this case the example shows how to use user-defined breaks and split the data by day/night for a latitude assumed to be London. References "],
["sec-percentileRose.html", "Section 5 Percentile roses 5.1 Introduction 5.2 Examples 5.3 Condtional probability function", " Section 5 Percentile roses 5.1 Introduction percentileRose calculates percentile levels of a pollutant and plots them by wind direction. One or more percentile levels can be calculated and these are displayed as either filled areas or as lines. By default, the function plots percentile concentrations in 10 degree segments. Alternatively, the levels by wind direction are calculated using a cyclic smooth cubic spline. The wind directions are rounded to the nearest 10 degrees, consistent with surface data from the UK Met Office before a smooth is fitted. The percentileRose function compliments other similar functions including windRose, pollutionRose, polarFreq or polarPlot. It is most useful for showing the distribution of concentrations by wind direction and often can reveal different sources e.g. those that only affect high percentile concentrations such as a chimney stack. Similar to other functions, flexible conditioning is available through the `type} option. It is easy for example to consider multiple percentile values for a pollutant by season, year and so on. See examples below. 5.2 Examples The first example is a basic plot of percentiles of O3 shown in Figure 5.1. percentileRose(mydata, pollutant = &quot;o3&quot;) Figure 5.1: A percentileRose plot of O3 concentrations at Marylebone Road. The percentile intervals are shaded and are shown by wind direction. It shows for example that higher concentrations occur for northerly winds, as expected at this location. However, it also shows, for example the actual value of the 95th percentile O3 concentration. A slightly more interesting plot is shown in Figure 5.2 for SO2 concentrations. We also take the opportunity of changing some default options. In this case it can be clearly seen that the highest concentrations of SO2 are dominated by east and south-easterly winds; likely reflecting the influence of stack emissions in those directions. percentileRose(mydata, pollutant = &quot;so2&quot;, percentile = c(25, 50, 75, 90, 95, 99, 99.9), col = &quot;brewer1&quot;, key.position = &quot;right&quot;, smooth = TRUE) Figure 5.2: A percentileRose plot of SO2 concentrations at Marylebone Road. The percentile intervals are shaded and are shown by wind direction. This plot sets some user-defined percentile levels to consider the higher SO2 concentrations, moves the key to the right and uses an alternative colour scheme. Lots more insight can be gained by considering how percentile values vary by other factors i.e. conditioning. For example, what do O3 concentrations look like split by season and whether it is daylight or nighttime hours? We can set the type to consider season and whether it is daylight or nighttime.2 This Figure reveals some interesting features. First, O3 concentrations are higher in the spring and summer and when the wind is from the north. O3 concentrations are higher on average at this site in spring due to the peak of northern hemispheric O3 and to some extent local production. This may also explain why O3 concentrations are somewhat higher at nighttime in spring compared with summer. Second, peak O3 concentrations are higher during daylight hours in summer when the wind is from the south-east. This will be due to more local (UK/European) production that is photochemically driven — and hence more important during daylight hours. percentileRose(mydata, type = c(&quot;season&quot;, &quot;daylight&quot;), pollutant = &quot;o3&quot;, col = &quot;Set3&quot;, mean.col = &quot;black&quot;) Figure 5.3: A percentileRose plot of O3 concentrations at Marylebone Road. The percentile intervals are shaded and are shown by wind direction.The plot shows the variation by season and whether it is nighttime or daylight hours. 5.3 Condtional probability function The percentileRose function can also plot conditional probability functions (CPF) (Ashbaugh, Malm, and Sadeh 1985). The CPF is defined as CPF = \\(m_\\theta/n_\\theta\\), where \\(m_\\theta\\) is the number of samples in the wind sector \\(\\theta\\) with mixing ratios greater than some `high’ concentration, and \\(n_\\theta\\) is the total number of samples in the same wind sector. CPF analysis is very useful for showing which wind directions are dominated by high concentrations and give the probability of doing so. In openair, a CPF plot can be produced as shown in 5.4. Note that in these plots only one percentile is provided and the method must be supplied. In 5.4 it is clear that the high concentrations (greater than the 95th percentile of all observations) is dominated by easterly wind directions. There are very low conditional probabilities of these concentrations being experienced for other wind directions. percentileRose(mydata, poll=&quot;so2&quot;, percentile = 95, method = &quot;cpf&quot;, col = &quot;darkorange&quot;, smooth = TRUE) Figure 5.4: A CPF plot of SO2 concentrations at Marylebone Road. It is easy to plot several species on the same plot and this works well because they all have the same probability scale (i.e. 0 to 1). In the example below (not shown) it is easy to see for each pollutant the wind directions that dominate the contributions to the highest (95th percentile) concentrations. For example, the highest CO and concentrations are totally dominated by south/south-westerly winds and the probability of their being such high concentrations from other wind directions is effectively zero. percentileRose(mydata, pollutant = c(&quot;nox&quot;, &quot;so2&quot;, &quot;o3&quot;, &quot;co&quot;, &quot;pm10&quot;, &quot;pm25&quot;), percentile = 95, method = &quot;cpf&quot;, col = &quot;darkorange&quot;, layout = c(3, 2)) Figure 5.5: A CPF plot of many pollutants at Marylebone Road. References "],
["sec-polarPlot.html", "Section 6 Polar plots 6.1 Introduction to polar plots 6.2 Examples 6.3 Nonparametric Wind Regression, NWR 6.4 Conditional Probability Function (CPF) plot 6.5 Pairwise statistics 6.6 Clustering", " Section 6 Polar plots This Sections considers the flexible polarPlot function that is used to provide information about source characteritics. The clustering of polar plots is also considered using polarCluster. 6.1 Introduction to polar plots The polarPlot function plots a bivariate polar plot of concentrations. Concentrations are shown to vary by wind speed and wind direction. In many respects they are similar to the plots shown in Section ?? but include some additional enhancements. These enhancements include: plots are shown as a continuous surface and surfaces are calculated through modelling using smoothing techniques. These plots are not entirely new as others have considered the joint wind speed-direction dependence of concentrations (see for example Yu et al. (2004)). However, plotting the data in polar coordinates and for the purposes of source identification is new. Furthermore, the basic polar plot is since been enhanced in many ways as described below. Publications that describe or use the technique are Carslaw et al. (2006) and Westmoreland et al. (2007). These plots have proved to be useful for quickly gaining a graphical impression of potential sources influences at a location. The polarPlot function is described in more detail in Carslaw et al. (2006) where it is used to triangulate sources in an airport setting, Carslaw and Beevers (2013) where it is used with a clustering technique to identify features in a polar plot with similar characteristics and Uria-Tellaetxe and Carslaw (2014) where it is extended to include a conditional probability function to extract more information from the plots. For many, maybe most situations, increasing wind speed generally results in lower concentrations due to increased dilution through advection and increased mechanical turbulence. There are, however, many processes that can lead to interesting concentration-wind speed dependencies, and we will provide a more theoretical treatment of this in due course. However, below are a few reasons why concentrations can change with increasing wind speeds. Buoyant plumes from tall stacks can be brought down to ground-level resulting in high concentrations under high wind speed conditions. Particle suspension increases with increasing wind speeds e.g. PM10 from spoil heaps and the like. ‘Particle’ suspension can be important close to coastal areas where higher wind speeds generate more sea spray. The wind speed dependence of concentrations in a street canyon can be very complex: higher wind speeds do not always results in lower concentrations due to re-circulation. Bivariate polar plots are very good at revealing these complexities. As Carslaw et al. (2006) showed, aircraft emissions have an unusual wind speed dependence and this can help distinguish them from other sources. If several measurement sites are available, polar plots can be used to triangulate different sources. Concentrations of NO2 can increase with increasing wind speed — or at least not decline steeply due to increased mixing. This mixing can result in O3-rich air converting NO to NO2. The function has been developed to allow variables other than wind speed to be plotted with wind direction in polar coordinates. The key issue is that the other variable plotted against wind direction should be discriminating in some way. For example, temperature can help reveal high-level sources brought down to ground level in unstable atmospheric conditions, or show the effect a source emission dependent on temperature e.g. biogenic isoprene. For research applications where many more variables could be available, discriminating sources by these other variables could be very insightful. Bivariate polar plots are constructed in the following way. First, wind speed, wind direction and concentration data are partitioned into wind speed-direction bins and the mean concentration calculated for each bin. Testing on a wide range of data suggests that wind direction intervals at 5–10\\(^\\circ\\) and 40 wind speed intervals capture sufficient detail of the concentration distribution. The wind direction data typically available are generally rounded to 10\\(^\\circ\\) and for typical surface measurements. Binning the data in this way is not strictly necessary but acts as an effective data reduction technique without affecting the fidelity of the plot itself. Furthermore, because of the inherent wind direction variability in the atmosphere, data from several weeks, months or years typically used to construct a bivariate polar plot tends to be diffuse and does not vary abruptly with either wind direction or speed and more finely resolved bin sizes or working with the raw data directly does not yield more information. The wind components, \\(u\\) and \\(v\\) are calculated i.e. \\[\\begin{equation} u = \\overline{u} . sin\\left(\\frac{2\\pi}{\\theta}\\right), v = \\overline{u} . cos\\left(\\frac{2\\pi}{\\theta}\\right) \\tag{6.1} \\end{equation}\\] with \\(\\overline{u}\\) is the mean hourly wind speed and \\(\\theta\\) is the mean wind direction in degrees with 90\\(^\\circ\\) as being from the east. The calculations above provides a \\(u\\), \\(v\\), concentration (\\(C\\)) surface. While it would be possible to work with this surface data directly a better approach is to apply a model to the surface to describe the concentration as a function of the wind components \\(u\\) and \\(v\\) to extract real source features rather than noise. A flexible framework for fitting a surface is to use a Generalized Additive Model (GAM) e.g. Hastie and Tibshirani (1990), Wood (2006). GAMs are a useful modelling framework with respect to air pollution prediction because typically the relationships between variables are non-linear and variable interactions are important, both of which issues can be addressed in a GAM framework. GAMs can be expressed as shown in Equation (6.2): \\[\\begin{equation} \\sqrt{C_i} = \\beta_0 + \\sum_{j=1}^{n}s_j(x_{ij}) + e_i \\tag{6.2} \\end{equation}\\] where \\(C_i\\) is the ith pollutant concentration, \\(\\beta_0\\) is the overall mean of the response, \\(s_j(x_{ij})\\) is the smooth function of ith value of covariate \\(j\\), \\(n\\) is the total number of covariates, and \\(e_i\\) is the \\(i\\)th residual. Note that \\(C_i\\) is square-root transformed as the transformation generally produces better model diagnostics e.g. normally distributed residuals. The model chosen for the estimate of the concentration surface is given by @ref(eq:mod}. In this model the square root-transformed concentration is a smooth function of the bivariate wind components \\(u\\) and \\(v\\). Note that the smooth function used is isotropic because \\(u\\) and \\(v\\) are on the same scales. The isotropic smooth avoids the potential difficulty of smoothing two variables on different scales e.g. wind speed and direction, which introduces further complexities. \\[\\begin{equation} \\sqrt{C_i} = s(u, v) + e_i \\tag{6.3} \\end{equation}\\] 6.2 Examples We first use the function in its simplest form to make a polar plot of NOx. The code is very simple as shown in Figure 6.1. polarPlot(mydata, pollutant = &quot;nox&quot;) Figure 6.1: Default use of the polarPlot function applied to Marylebone Road NOx concentrations. This produces Figure 6.1. The scale is automatically set using whatever units the original data are in. This plot clearly shows highest NOx concentrations when the wind is from the south-west. Given that the monitor is on the south side of the street and the highest concentrations are recorded when the wind is blowing away from the monitor is strong evidence of street canyon recirculation. Figure 6.2 and Figure 6.3 shows polar plots using different defaults and for other pollutants. In the first (Figure 6.2, a different colour scheme is used and some adjustments are made to the key. In Figure 6.3, SO2 concentrations are shown. What is interesting about this plot compared with either Figure 6.2 or Figure 6.1 is that the concentration pattern is very different i.e. high concentrations with high wind speeds from the east. The most likely source of this SO2 are industrial sources to the east of London. The plot does still however show evidence of a source to the south-west, similar to the plot for NOx, which implies that road traffic sources of SO2 can also be detected. These plots often show interesting features at higher wind speeds. For these conditions there can be very few measurements and therefore greater uncertainty in the calculation of the surface. There are several ways in which this issue can be tackled. First, it is possible to avoid smoothing altogether and use polarFreq. The problem with this approach is that it is difficult to know how best to bin wind speed and direction: the choice of interval tends to be arbitrary. Second, the effect of setting a minimum number of measurements in each wind speed-direction bin can be examined through min.bin. It is possible that a single point at high wind speed conditions can strongly affect the surface prediction. Therefore, setting min.bin = 3, for example, will remove all wind speed-direction bins with fewer than 3 measurements before fitting the surface. This is a useful strategy for testing how sensitive the plotted surface is to the number of measurements available. While this is a useful strategy to get a feel for how the surface changes with different min.bin settings, it is still difficult to know how many points should be used as a minimum. Third, consider setting uncertainty = TRUE. This option will show the predicted surface together with upper and lower 95% confidence intervals, which take account of the frequency of measurements. The uncertainty approach ought to be the most robust and removes any arbitrary setting of other options. There is a close relationship between the amount of smoothing and the uncertainty: more smoothing will tend to reveal less detail and lower uncertainties in the fitted surface and vice-versa. The default however is to down-weight the bins with few data points when fitting a surface. Weights of 0.25, 0.5 and 0.75 are used for bins containing 1, 2 and 3 data points respectively. The advantage of this approach is that no data are actually removed (which is what happens when using min.bin). This approach should be robust in a very wide range of situations and is also similar to the approaches used when trying to locate sources when using back trajectories as described in Section ??. Users can ignore the automatic weighting by supplying the option weights = c(1, 1, 1). ## NOx plot polarPlot(mydata, pollutant = &quot;nox&quot;, col = &quot;jet&quot;, key.position = &quot;bottom&quot;, key.header = &quot;mean nox (ug/m3)&quot;, key.footer = NULL) Figure 6.2: Example plots using the polarPlot function with different options for the mean concentration of NOx. polarPlot(mydata, pollutant = &quot;so2&quot;) Figure 6.3: Example plots using the polarPlot function for the mean concentration of SO2. A very useful approach for understanding air pollution is to consider ratios of pollutants. One reason is that pollutant ratios can be largely independent of meteorological variation. In many circumstances it is possible to gain a lot of insight into sources if pollutant ratios are considered. First, it is necessary to calculate a ratio, which is easy in R. In this example we consider the ratio of SO2/NOx: library(tidyverse) mydata &lt;- mutate(mydata, ratio = so2 / nox) This makes a new variable called ratio. Sometimes it can be problematic if there are values equal to zero on the denominator, as is the case here. The mean and maximum value of the ratio is infinite, as shown by the Inf in the statistics below. Luckily, R can deal with infinity and the openair functions will remove these values before performing calculations. It is very simple therefore to calculate ratios. summary(mydata$ratio) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.000 0.018 0.024 Inf 0.034 Inf 11782 A polar plot of the SO2/NOx ratio is shown in Figure 6.4. The plot highlights some new features not seen before. First, to the north there seems to be evidence that the air tends to have a higher SO2/NOx ratio. Also, the source to the east has a higher SO2/NOx ratio compared with that when the wind is from the south-west i.e. dominated by road sources. It seems therefore that the easterly source(s), which are believed to be industrial sources have a different SO2/NOx ratio compared with road sources. This is a very simple analysis, but ratios can be used effectively in many functions and are particularly useful in the presence of high source complexity. polarPlot(mydata, pollutant = &quot;ratio&quot;, main = &quot;so2/nox ratio&quot;) Figure 6.4: Bivariate polar plot of the ratio of SO2/NOx. Sometimes when considering ratios it might be necessary to limit the values in some way; perhaps due to some unusually low value denominator data resulting in a few very high values for the ratio. This is easy to do with the dplyr filter command. The code below selects ratios less than 0.1. polarPlot(filter(mydata, ratio &lt; 0.1), pollutant = &quot;ratio&quot;) The uncertainties in the surface can be calculated by setting the option uncertainty = TRUE. The details are described above and here we show the example of SO2 concentrations (Figure 6.5. In general the uncertainties are higher at high wind speeds i.e. at the ‘fringes’ of a plot where there are fewer data. However, the magnitude depends on both the frequency and magnitude of the concentration close to the points of interest. The pattern of uncertainty is not always obvious and it can differ markedly for different pollutants. polarPlot(mydata, pollutant = &quot;so2&quot;, uncertainty = TRUE) Figure 6.5: Bivariate polar plot of SO2 concentrations at Marylebone Road. Three surfaces are shown: the central prediction (middle) and the lower and upper 95% estimated uncertainties. These plots help to show that in this particular case, some of the concentrations for strong easterly and south-easterly winds are rather uncertain. However, the central feature to the east remains, suggesting this feature is real and not an artifact of there being too few data. The polarPlot function can also produce plots dependent on another variable (see the type option). For example, the variation of SO2 concentrations at Marylebone Road by hour of the day in the code below. The function was called as shown in below, and in this case the minimum number of points in each wind speed/direction was set to 2. polarPlot(mydata, pollutant = &quot;so2&quot;, type = &quot;hour&quot;, min.bin = 2) This plot shows that concentrations of SO2 tend to be highest from the east (as also shown in Figure 6.3) and for hours in the morning. Together these plots can help better understand different source types. For example, does a source only seem to be present during weekdays, or winter months etc. In the case of type = \"hour\", the more obvious presence during the morning hours could be due to meteorological factors and this possibility should be investigated as well. In other settings where there are many sources that vary in their source emission and temporal characteristics, the polarPlot function should prove to be very useful. One issue to be aware of is the amount of data required to generate some of these plots; particularly the hourly plots. If only a relatively short time series is available there may not be sufficient information to produce useful plots. Whether this is important or not will depend on the specific circumstances e.g. the prevalence of wind speeds and directions from the direction of interest. When used to produce many plots (e.g. type = \"hour\"), the run time can be quite long. 6.3 Nonparametric Wind Regression, NWR An alternative approach to modelling the surface concentrations with a GAM is to use kernel smoothers, as described by Henry et al. (2009). In NWR, smoothing is achieved using nonparametric kernel smoothers that weight concentrations on a surface according to their proximity to defined wind speed and direction intervals. In the approach adopted in openair (which is not identical to Henry et al. (2009)), Gaussian smoothers are used for both wind direction and wind speed. Unlike the default GAM approach in openair, the NWR technique works directly with the raw (often hourly) data. It tends to provide similar results to openair but may have advantages in certain situations e.g. when there is insufficient data available to use a GAM. The width of the Gaussian kernels (\\(\\sigma\\)) is controlled by the options wd_spread and ws_spread. An example for SO2 concentrations is shown in Figure 6.6, which can be compared with Figure 6.3. polarPlot(mydata, pollutant = &quot;so2&quot;, statistic = &quot;nwr&quot;) Figure 6.6: polarPlot of SO2 concentrations at Marylebone Road based on the NWR approach. 6.4 Conditional Probability Function (CPF) plot The conditional probability functions (CPF) was described on in the context of the percentileRose function. The CPF was originally used to show the wind directions that dominate a (specified) high concentration of a pollutant; showing the probability of such concentrations occurring by wind direction Ashbaugh, Malm, and Sadeh (1985). However, these ideas can very usefully be applied to bivariate polar plots. In this case the CPF is defined as CPF = \\(m_{\\theta,j}/n_{\\theta,j}\\), where \\(m_{\\theta,j}\\) is the number of samples in the wind sector \\(\\theta\\) and wind speed interval \\(j\\) with mixing ratios greater than some ‘high’ concentration, and \\(n_{\\theta, j}\\) is the total number of samples in the same wind direction-speed interval. Note that \\(j\\) does not have to be wind speed but could be any numeric variable e.g. ambient temperature. CPF analysis is very useful for showing which wind direction, wind speed intervals are dominated by high concentrations and give the probability of doing so. A full explanation of the development and use of the bivariate case of the CPF is described in Uria-Tellaetxe and Carslaw (2014) where it is applied to monitoring data close to steelworks. polarPlot(mydata, pollutant = &quot;so2&quot;, statistic = &quot;cpf&quot;, percentile = 90) Figure 6.7: polarPlot of SO2 concentrations at Marylebone Road based on the CPF function. An example of a CPF polar plot is shown in Figure 6.7 for the 90th percentile concentration of SO2. This plot shows that for most wind speed-directions the probability of SO2 concentrations being greater than the 90th percentile is zero. The clearest areas where the probability is higher is to the east. Indeed, the plot now clearly reveals two potential sources of SO2, which are not as apparent in the ‘standard’ plot shown in Figure 6.3. Note that Figure 6.7 also gives the calculated percentile at the bottom of the plot (9.2 ppb in this case). Figure 6.7 can also be compared with the CPF plot based only on wind direction shown in Figure 5.4. While Figure 5.4 very clearly shows that easterly wind dominate high concentrations of SO2, Figure 6.7 provides additional valuable information by also considering wind speed, which in this case is able to discriminate between two sources (or groups of sources) to the east. The polar CPF plot is therefore potentially very useful for source identification and characterisation. It is, for example, worth also considering other percentile levels and other pollutants. For example, considering the 95th percentile for SO2 ‘removes’ one of the sources (the one at highest wind speed). This helps to show some maybe important differences between the sources that could easily have been missed. Similarly, considering other pollutants can help build up a good understanding of these sources. A CPF plot for NO2 at the 90th percentile shows the single dominance of the road source. However, a CPF plot at the 75th percentile level indicates source contributions from the east (likely tall stacks), which again are not as clear in the standard bivariate polar plot. Considering a range of percentile values can therefore help to build up a more complete understanding of source contributions. polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(0, 10)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(10, 20)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(20, 30)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(30, 40)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(40, 50)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(50, 60)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(60, 70)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(70, 80)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(80, 90)) polarPlot(mydata, poll = &quot;so2&quot;, stati = &quot;cpf&quot;, percentile = c(90, 100)) Figure 6.8: polarPlot of SO2 concentrations at Marylebone Road based on the CPF function for a range of percentile intervals from 0–10, 10–20, … , 90–100. However, even more useful information can be gained by considering intervals of percentiles e.g. 50–60, 60–70 etc. By considering intervals of percentiles it becomes clear that some sources only affect a limited percentile range. polarPlot can accept a percentile argument of length two e.g. percentile = c(80, 90). In this case concentrations in the range from the lower to upper percentiles will be considered. In Figure 6.8 for example, it is apparent that the road source to the south west is only important between the 60 to 90th percentiles. As mentioned previously, the chimney stacks to the east are important for the higher percentiles (90 to 100). What is interesting though is the emergence of what appears to be other sources at the lower percentile intervals. These potential sources are not apparent in Figure 6.3. The other interesting aspect is that it does seem that specific sources tend to be prominent for specific percentile ranges. If this characteristic is shown to be the case more generally, then CPF intervals could be a powerful way in which to identify many sources. Whether these particular sources are important or not is questionable and depends on the aims of the analysis. However, there is no reason to believe that the potential sources shown in the percentile ranges 0 to 50 are artefacts. They could for example be signals from more distant point sources whose plumes have diluted more over longer distances. Such sources would be ‘washed out’ in an ordinary polar plot. For a fuller example of this approach see Uria-Tellaetxe and Carslaw (2014). Note that it is easy to work out what the concentration intervals are for the percentiles shown in Figure 6.8: quantile(mydata$so2, probs = seq(0, 1, by = 0.1), na.rm = TRUE) ## 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% ## 0.0000 1.0125 1.8825 2.5000 3.2500 4.0000 4.9375 5.9100 7.2375 9.2500 ## 100% ## 63.2050 To plot the Figures on one page it is necessary to make the plot objects first and then decide how to plot them. To plot the Figures in a particular layout see ??. 6.5 Pairwise statistics Grange, Lewis, and Carslaw (2016) further developed the capabilities of the polarPlot function by allowing pairwise statistics to be used. This method makes it possible to consider the relationship between two pollutants to be considered. The relationship between two pollutants often yields useful source apportionment information and when combined with the polarPlot function can provide enhanced information. The pairwise statistics that can be considered include: The Pearson or Spearman correlation coefficient, \\(r\\); The robust slope (gradient) resulting from a linear regressions between two pollutants. The quantile slope from a quantile regression applied to two variables with a quantile value of \\(tau\\). By default, the median slope (i.e. \\(tau\\) = 0.5) is used by the actual level can be set by the user. The calculation involves a weighted Pearson correlation coefficient, which is weighted by Gaussian kernels for wind direction and the radial variable (by default wind speed). More weight is assigned to values close to a wind speed-direction interval. Kernel weighting is used to ensure that all data are used rather than relying on the potentially small number of values in a wind speed-direction interval. The calculation involves a weighted statistics by Gaussian kernels for wind direction and the radial variable (by default wind speed). More weight is assigned to values close to a wind speed-direction interval. Kernel weighting is used to ensure that all data are used rather than relying on the potentially small number of values in a wind speed-direction interval. An example usage scenario is that measurements of metal concentrations are made close to a steelworks where there is interest in understanding the principal sources. While it is useful to consider the correlation between potentially many metal concentrations, the contention is that if the correlation is also considered as a function of wind speed and direction, improved information will be available of the types of sources contributing. For example, it may be that Fe and Mn are quite strongly correlated overall, but they tend to be most correlated under specific wind speed and direction ranges — suggesting a specific source origin. As an example of usage we will consider the relationship between PM2.5 and PM10 at the rural Harwell site in Oxfordshire. Additionally, we will use meteorological data from a nearby site rather than rely on modelled values that are provided in importAURN. library(worldmet) # to access met data library(tidyverse) har &lt;- importAURN(&quot;har&quot;, year = 2013) # import met data from nearby site (Benson) met &lt;- importNOAA(code = &quot;036580-99999&quot;, year = 2013) # merge AQ and met but don&#39;t use modelled ws and wd har &lt;- inner_join( select(har, -ws, -wd, -air_temp), met, by = &quot;date&quot; ) An example pairwise regression surface relationship relating PM2.5 and PM10 is shown in Figure 6.9. This plot reveals that almost all the PM10 is in the form of PM2.5 when the wind has an easterly component, which is attributed to the large secondary contribution likely dominated by ammonium nitrate. A simple scatter plot between PM2.5 and PM10 strongly suggests a 1:1 relationship and it is not obvious that there is a higher PM2.5/PM10 ratio when the wind is from the east. polarPlot(har, poll = c(&quot;pm2.5&quot;, &quot;pm10&quot;), statistic = &quot;robust_slope&quot;, col = &quot;jet&quot;, limits = c(0, 1), ws_spread = 1.5, wd_spread = 10) Figure 6.9: Use of the polarPlot function to investigate the linear regression slope between PM2.5 and PM10 at Harwell in 2013. In this case the robust slope is calculated. 6.6 Clustering The polarPlot function will often identify interesting features that would be useful to analyse further. It is possible to select areas of interest based only on a consideration of a plot. Such a selection could be based on wind direction and wind speed intervals for example e.g. subdata &lt;- filter(mydata, ws &gt; 3, wd &gt;= 180, wd &lt;= 270) which would select wind speeds &gt;3 m s-1 and wind directions from 180 to 270 degrees from mydata. That subset of data, subdata, could then be analysed using other functions. While this approach may be useful in many circumstances it is rather arbitrary. In fact, the choice of ‘interesting feature’ in the first place can even depend on the colour scale used, which is not very robust. Furthermore, many interesting patterns can be difficult to select and won’t always fall into convenient intervals of other variables such as wind speed and direction. A better approach is to use a method that can select group similar features together. One such approach is to use cluster analysis. openair uses k-means clustering as a way in which bivariate polar plot features can be identified and grouped. The main purpose of grouping data in this way is to identify records in the original time series data by cluster to enable post-processing to better understand potential source characteristics. The process of grouping data in k-means clustering proceeds as follows. First, \\(k\\) points are randomly chosen form the space represented by the objects that are being clustered into \\(k\\) groups. These points represent initial group centroids. Each object is assigned to the group that has the closest centroid. When all objects have been assigned, the positions of the \\(k\\) centroids is re-calculated. The previous two steps are repeated until the centroids no longer move. This produces a separation of the objects into groups from which the metric to be minimised can be calculated. Central to the idea of clustering data is the concept of distance i.e. some measure of similarity or dissimilarity between points. Clusters should be comprised of points separated by small distances relative to the distance between the clusters. Careful consideration is required to define the distance measure used because the effectiveness of clustering itself fundamentally depends on its choice. The similarity of concentrations shown in Figure 6.1 for example is determined by three variables: the \\(u\\) and \\(v\\) wind components and the concentration. All three variables are equally important in characterising the concentration-location information, but they exist on different scales i.e. a wind speed-direction measure and a concentration. Let \\(X = \\{x_i\\}, i = 1,\\ldots,n\\) be a set of \\(n\\) points to be clustered into \\(K\\) clusters, \\(C = \\{c_k, k = 1,\\ldots,K\\}\\). The basic k-means algorithm for \\(K\\) clusters is obtained by minimising: \\[\\begin{equation} \\sum_{k=1}^{K} \\sum_{x_i \\in c_k} || x_i - \\mu_k ||^2 \\tag{6.4} \\end{equation}\\] where \\(|| x_i - \\mu_k ||^2\\) is a chosen distance measure, \\(\\mu_k\\) is the mean of cluster \\(c_k\\). The distance measure is defined as the Euclidean distance: \\[\\begin{equation} d_{x, y} = \\left({\\sum_{j=1}^{J} (x_j - y_j) ^ 2}\\right)^{1/2} \\tag{6.5} \\end{equation}\\] Where x and y are two J-dimensional vectors, which have been standardized by subtracting the mean and dividing by the standard deviation. In the current case \\(J\\) is of length three i.e. the wind components \\(u\\) and \\(v\\) and the concentration \\(C\\), each of which is standardized e.g.: \\[\\begin{equation} x_j = \\left(\\frac{x_j - \\overline{x}}{\\sigma_x}\\right) \\tag{6.6} \\end{equation}\\] Standardization is necessary because the wind components \\(u\\) and \\(v\\) are on different scales to the concentration. In principle, more weight could be given to the concentration rather than the \\(u\\) and \\(v\\) components, although this would tend to identify clusters with similar concentrations but different source origins. polarCluster can be thought of as the ‘local’ version of clustering of back trajectories. Rather than using air mass origins, wind speed, wind direction and concentration are used to group similar conditions together. Section ?? provides the details of clustering back trajectories in openair. A fuller description of the clustering approach is described in Carslaw and Beevers (2013). The use of the polarCluster is very similar to the use of all openair functions. While there are many techniques available to try and find the optimum number of clusters, it is difficult for these approaches to work in a consistent way for identifying features in bivariate polar plots. For this reason it is best to consider a range of solutions that covers a number of clusters. Cluster analysis is computationally intensive and the polarCluster function can take a comparatively long time to run. The basic idea is to calculate the solution to several cluster levels and then choose one that offers the most appropriate solution for post-processing. The example given below is for concentrations of SO2, shown in Figure 6.3 and the aim is to identify features in that plot. A range of numbers of clusters will be calculated — in this case from two to ten. polarCluster(mydata, pollutant=&quot;so2&quot;, n.clusters=2:10, cols= &quot;Set2&quot;) Figure 6.10: Use of the polarCluster function applied to SO2 concentrations at Marylebone Road. In this case 2 to 10 clusters have been chosen. results &lt;- polarCluster(mydata, pollutant=&quot;so2&quot;, n.clusters = 8, cols = &quot;Set2&quot;) Figure 6.11: Use of the polarCluster function applied to SO2 concentrations at Marylebone Road. In this case 8 clusters have been chosen. The real benefit of polarCluster is being able to identify clusters in the original data frame. To do this, the results from the analysis must be read into a new variable, as in Figure 6.11, where the results are read into a data frame `results}. Now it is possible to use this new information. In the 8-cluster solution to Figure 6.11, cluster~6 seems to capture the elevated SO2 concentrations to the east well (see Figure 6.3 for comparison), while cluster 5 will strongly represent the road contribution. The results are here: head(results[[&quot;data&quot;]]) ## .id date ws wd nox no2 o3 pm10 so2 co pm25 ## 1 1 1998-01-01 00:00:00 0.60 280 285 39 1 29 4.7225 3.3725 NA ## 2 10 1998-01-01 09:00:00 3.96 170 113 39 2 12 2.9225 1.2050 NA ## 3 100 1998-01-05 03:00:00 8.76 240 53 24 16 12 1.5950 0.5400 NA ## 4 1000 1998-02-11 15:00:00 7.20 230 372 92 2 49 8.5950 3.7175 NA ## 5 10000 1999-02-21 15:00:00 6.36 290 71 32 20 10 2.6225 1.0500 8 ## 6 10001 1999-02-21 16:00:00 7.68 290 85 39 16 12 2.8700 1.4750 9 ## ws2 wd2 ratio cluster ## 1 -3.644413 300.8006 0.01657018 4 ## 2 8.097406 205.4476 0.02586283 5 ## 3 10.273961 316.2100 0.03009434 4 ## 4 5.470734 211.1890 0.02310484 4 ## 5 3.362746 349.8437 0.03693662 7 ## 6 6.596460 286.0474 0.03376471 7 Note that there is an additional column cluster that gives the cluster a particular row belongs to and that this is a character variable. It might be easier to read these results into a new data frame: results &lt;- results[[&quot;data&quot;]] It is easy to find out how many points are in each cluster: table(results[[&quot;cluster&quot;]]) ## ## 1 2 3 4 5 6 7 8 ## 206 412 160 24133 16049 2590 7925 2832 Now other openair analysis functions can be used to analyse the results. For example, to consider the temporal variations by cluster: timeVariation(results, pollutant = &quot;so2&quot;, group = &quot;cluster&quot;, key.columns = 4, col = &quot;Set2&quot;, ci = FALSE, lwd = 3) Figure 6.12: Temporal variation in SO2 split by cluster. Or if we just want to plot a couple of clusters (5 and 6) using the same colours as in Figure 6.11: timeVariation(filter(results, cluster %in% c(&quot;5&quot;, &quot;6&quot;)), pollutant = &quot;so2&quot;, group = &quot;cluster&quot;, col = openColours(&quot;Set2&quot;, 8)[5:6], lwd = 3) Figure 6.13: Temporal variation in SO2 split by cluster — showing only two clusters. polarCluster will work on any surface that can be plotted by polarPlot e.g. the radial variable does not have to be wind speed but could be another variable such as temperature. While it is not always possible for polarCluster to identify all features in a surface it certainly makes it easier to post-process polarPlots using other openair functions or indeed other analyses altogether. Another useful way of understanding the clusters is to use the timeProp function, which can display a time series as a bar chart split by a categorical variable (in this case the cluster). In this case it is useful to plot the time series of SO2 and show how much of the concentration is contributed to by each cluster. Such a plot is shown in Figure 6.14. It is now easy to see for example that many of the peaks in SO2 are associated with cluster 6 (power station sources from the east), seen in Figure 6.11. Cluster~6 is particularly prominent during springtime, but those sources also make important contributions through the whole year. timeProp(selectByDate(results, year = 2003), pollutant = &quot;so2&quot;, avg.time = &quot;day&quot;, proportion= &quot;cluster&quot;, col = &quot;Set2&quot;, key.position = &quot;top&quot;, key.columns = 8, date.breaks = 10, ylab = &quot;so2 (ug/m3)&quot;) Figure 6.14: Temporal variation in daily SO2 concentration at the Marylebone Road site show by contribution of each cluster for 2003. References "],
["sec-timeVariation.html", "Section 7 Temporal variations 7.1 Purpose 7.2 Applications 7.3 Output", " Section 7 Temporal variations 7.1 Purpose In air pollution, the variation of a pollutant by time of day and day of week can reveal useful information concerning the likely sources. For example, road vehicle emissions tend to follow very regular patterns both on a daily and weekly basis. By contrast some industrial emissions or pollutants from natural sources (e.g. sea salt aerosol) may well have very different patterns. The timeVariation function produces four plots: day of the week variation, mean hour of day variation and a combined hour of day – day of week plot and a monthly plot. Also shown on the plots is the 95% confidence interval in the mean. These uncertainty limits can be helpful when trying to determine whether one candidate source is different from another. The uncertainty intervals are calculated through bootstrap re-sampling, which will provide better estimates than the application of assumptions based on normality, particularly when there are few data available. The function can consider one or two input variables. In addition, there is the option of ‘normalising’ concentrations (or other quantities). Normalising is very useful for comparing the patterns of two different pollutants, which often cover very different ranges in concentration. Normalising is achieved by dividing the concentration of a pollutant by its mean value. Note also that any other variables besides pollutant concentrations can be considered e.g. meteorological or traffic data. There is also an option difference which is very useful for considering the difference in two time series and how they vary over different temporal resolutions. Again, bootstrap re-sampling methods are used to estimate the uncertainty of the difference in two means. Care has been taken to ensure that wind direction (wd) is vector-averaged. Less obvious though is the uncertainty in wind direction. A pragmatic approach has been adopted here that considers how wind direction changes. For example, consider the following wind directions: 10, 10, 10, 180, 180, 180\\(^\\circ\\) The standard deviation of these numbers is 93\\(^\\circ\\). However, what actually occurs is the wind direction is constant at 10\\(^\\circ\\) then switches to 180\\(^\\circ\\). In terms of changes there is a sequence of numbers: 0, 0, 170, 0, 0 with a standard deviation of 76\\(^\\circ\\). We use the latter method as a basis of calculating the 95% confidence intervals in the mean. There are also problems with simple averaging—for example, what is the average of 20 and 200\\(^\\circ\\). It can’t be known. In some situations where the wind direction is bi-modal with differences around 180\\(^\\circ\\), the mean can be ‘unstable’. For example, wind that is funnelled along a valley forcing it to be either easterly or westerly. Consider for example the mean of 0\\(^\\circ\\) and 179\\(^\\circ\\) (89.5\\(^\\circ\\)), but a small change in wind direction to 181\\(^\\circ\\) gives a mean of 270.5\\(^\\circ\\). Some care should be exercised therefore when averaging wind direction. It is always a good idea to use thewindRosefunction with type set to ‘month’ or ‘hour’. The timeVariation function is probably one of the most useful functions that can be used for the analysis of air pollution. Here are a few uses/advantages: Variations in time are one of the most useful ways of characterising air pollution for a very wide range of pollutants including local urban pollutants and tropospheric background concentrations of ozone and the like. The function works well in conjunction with other functions such as polarPlot (see Section 6), where the latter may identify conditions of interest (say a wind speed/direction range). By sub-setting for those conditions in timeVariation the temporal characteristics of a particular source could be characterised and perhaps contrasted with another subset of conditions. The function can be used to compare a wide range of variables, if available. Suggestions include meteorological e.g. boundary layer height and traffic flows. The function can be used for comparing pollutants over different sites. See Section (??) for examples of how to do this. The function can be used to compare one part of a time series with another. This is often a very powerful thing to do, particularly if concentrations are normalised. For example, there is often interest in knowing how diurnal/weekday/seasonal patterns vary with time. If a pollutant showed signs of an increase in recent years, then splitting the data set and comparing each part together can provide information on what is driving the change. Is there, for example, evidence that morning rush hour concentrations have become more important, or Sundays have become relatively more important? An example is given below using the splitByDate function. timeVariation can be used to consider the differences between two time series, which will have multiple benefits. For example, for model evaluation it can be very revealing to consider the difference between observations and modelled values over different time scales. Considering such differences can help reveal the character and some reasons for why a model departs from reality. 7.2 Applications We apply the timeVariation function to PM10 concentrations and take the opportunity to filter the data to maximise the signal from the road. The polarPlot function described in Section (Section 6) is very useful in this respect in highlighting the conditions under which different sources have their greatest impact. A subset of data is used filtering for wind speeds &gt; 3 m s-1 and wind directions from 100–270 degrees. The code used is: The results are shown in Figure 7.1. The plot shown at the top-left shows the diurnal variation of concentrations for all days. It shows for example that PM10 concentrations tend to peak around 9 am. The shading shows the 95% confidence intervals of the mean. The plot at the top-right shows how PM10 concentrations vary by day of the week. Here there is strong evidence that PM10 is much lower at the weekends and that there is a significant difference compared with weekdays. It also shows that concentrations tend to increase during the weekdays. Finally, the plot at the bottom shows both sets of information together to provide an overview of how concentrations vary. Note that the plot need not just consider pollutant concentrations. Other useful variables (if available) are meteorological and traffic flow or speed data. Often, the combination of several sets of data can be very revealing. The filter function is extremely useful in this respect. For example, if it were believed that a source had an effect under specific conditions; they can be isolated with the filter function. It is also useful if it is suspected that two or more sources are important that they can be isolated to some degree and compared. This is where the uncertainty intervals help — they provide an indication whether the behaviour of one source differs significantly from another. library(openair) library(tidyverse) timeVariation(filter(mydata, ws &gt; 3, wd &gt; 100, wd &lt; 270), pollutant = &quot;pm10&quot;, ylab = &quot;pm10 (ug/m3)&quot;) Figure 7.1: Example plot using the timeVariation function to plot PM10 concentrations at Marylebone Road. Figure 7.2 shows the function applied to concentrations of NOx, CO, NO2 and O3 concentrations. In this case the concentrations have been normalised. The plot clearly shows the markedly different temporal trends in concentration. For CO, there is a very pronounced increase in concentrations during the peak pm rush hour. The other important difference is on Sundays when CO concentrations are relatively much higher than NOx. This is because flows of cars (mostly petrol) do not change that much by day of the week, but flows of vans and HGVs (diesel vehicles) are much less on Sundays. Note, however, that the monthly trend is very similar in each case — which indicates very similar source origins. Taken together, the plots highlight that traffic emissions dominate this site for CO and NOx, but there are important difference in how these emissions vary by hour of day and day of week. Also shown in the very different behaviour of O3. Because O3 reacts with NO, concentrations of NOx and O3 tend to be anti-correlated. Note also the clear peak in O3 in April/May, which is due to higher northern hemispheric background concentrations in the spring. Even at a busy roadside site in central London this influence is clear to see. timeVariation(mydata, pollutant = c(&quot;nox&quot;, &quot;co&quot;, &quot;no2&quot;, &quot;o3&quot;), normalise = TRUE) Figure 7.2: Example plot using the timeVariation function to plot NOx, CO, NO2 and O3 concentrations at Marylebone Road. In this plot, the concentrations are normalised. Another example is splitting the data set by time. We use the splitByDate function to divide up the data into dates before January 2003 and after January 2003. This time the option difference is used to highlight how NO2 concentrations have changed over these two periods. The results are shown in Figure 7.3. There is some indication in this plot that data after 2003 seem to show more of a double peak in the diurnal plots; particularly in the morning rush hour. Also, the difference line does more clearly highlight a more substantial change over weekdays and weekends. Given that cars are approximately constant at this site each day, the change may indicate a change in vehicle emissions from other vehicle types. Given that it is known that primary NO2 emissions are known to have increased sharply from the beginning of 2003 onwards, this perhaps provides clues as to the principal cause. ## split data into two periods (see Utlities section for more details) mydata &lt;- splitByDate(mydata, dates= &quot;1/1/2003&quot;, labels = c(&quot;before Jan. 2003&quot;, &quot;After Jan. 2003&quot;)) timeVariation(mydata, pollutant = &quot;no2&quot;, group = &quot;split.by&quot;, difference = TRUE) Figure 7.3: Example plot using the timeVariation function to plot NO2 concentrations at Marylebone Road. In this plot, the concentrations are shown before and after January 2003. In the next example it is shown how to compare one subset of data of interest with another. Again, there can be many reasons for wanting to do this and perhaps the data set at Marylebone Road is not the most interesting to consider. Nevertheless, the code below shows how to approach such a problem. The scenario would be that one is interested in a specific set of conditions and it would be useful to compare that set, with another set. A good example would be from an analysis using the polarPlot function where a ‘feature’ of interest has been identified—maybe an indication of a different source. But does this potentially different source behave differently in terms of temporal variation? If it does, then maybe that provides evidence to support that it is a different source. In a wider context, this approach could be used in many different ways depending on available data. A good example is the analysis of model output where many diagnostic meteorological data are available. This is an area that will be developed. The approach here is to first make a new variable called feature' and fill it with the valueother’. A subset of data is defined and the associated locations in the data frame identified. The subset of data is then used to update the `feature’ field with a new description. This approach could be extended to some quite complex situations. There are a couple of things to note in Figure 7.2. There seems to be evidence that for easterly winds &gt; 4 m s-1 that concentrations of SO2 are lower at night. Also, there is some evidence that concentrations for these conditions are also lower at weekends. This might reflect that SO2 concentrations for these conditions tend to be dominated by tall stack emissions that have different activities to road transport sources. This technique will be returned to with different data sets in future. ## make a field called &quot;site&quot; and fill: make all values = &quot;other&quot; mydata$feature &lt;- &quot;other&quot; ## now find which indexes correspond to easterly conditions &gt; 4m/s ws id &lt;- which(with(mydata, ws &gt; 4 &amp; wd &gt; 0 &amp; wd &lt;= 180 )) ## use the ids to update the site column ## there are now two values in site: &quot;other&quot; and &quot;easterly&quot; mydata$feature[id] &lt;- &quot;easterly&quot; timeVariation(mydata, pollutant =&quot;so2&quot;, group = &quot;feature&quot;, ylab = &quot;so2 (ppb)&quot;, difference = TRUE) Figure 7.4: Example plot using the timeVariation function to plot SO2 concentrations at Marylebone Road. In this plot, the concentrations are shown for a subset of easterly conditions and everything else. Note that the uncertainty in the mean values for easterly winds is greater than other. This is mostly because the sample size is much lower for easterly compared with other. By default timeVariation shows the mean variation in different temporal components and the 95% confidence interval in the mean. However, it is also possible to show how the data are distributed by using a different option for statistic. When statistic = \"median\" the median line is shown together with the 25/75th and 5/95th quantile values. Users can control the quantile values shown be setting the conf.int. For example, conf.int = c(0.25, 0.99) will show the median, 25/75th and 1/99th quantile values. The statistic = \"median\" option is therefore very useful for showing how the data are distributed — somewhat similar to a box and whisker plot. Note that it is expected that only one pollutant should be shown when statistic = \"median\" is used due to potential over-plotting; although the function will display several species of required. An example is shown in Figure 7.5 for PM10 concentrations. timeVariation(mydata, pollutant = &quot;pm10&quot;, statistic = &quot;median&quot;, col = &quot;firebrick&quot;) Figure 7.5: Example plot using the timeVariation function to show the variation in the median, 25/75th and 5/95th quantile values for PM10. The shading shows the extent to the 25/75th and 5/95th quantiles. 7.3 Output The timeVariation function produces several outputs that can be used for further analysis or plotting. It is necessary to read the output into a variable for further processing. The code below shows the different objects that are returned and the code shows how to access them. myOutput &lt;- timeVariation(mydata, pollutant = &quot;so2&quot;) ## show the first part of the day/hour variation ## note that value = mean, and Upper/Lower the 95% confid. intervals head(myOutput$data$day.hour) ## # A tibble: 6 x 8 ## # Groups: ci [1] ## variable wkday hour default Mean Lower Upper ci ## &lt;fct&gt; &lt;ord&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 so2 Monday 0 01 January 1998 to 23 June 2… 2.93 2.63 3.19 0.95 ## 2 so2 Tuesday 0 01 January 1998 to 23 June 2… 3.21 3.02 3.46 0.95 ## 3 so2 Wednesday 0 01 January 1998 to 23 June 2… 3.35 3.09 3.59 0.95 ## 4 so2 Thursday 0 01 January 1998 to 23 June 2… 3.22 2.98 3.56 0.95 ## 5 so2 Friday 0 01 January 1998 to 23 June 2… 3.64 3.39 3.90 0.95 ## 6 so2 Saturday 0 01 January 1998 to 23 June 2… 4.25 4.01 4.58 0.95 ## can make a new data frame of this data e.g. day.hour &lt;- myOutput$data$day.hour head(day.hour) ## # A tibble: 6 x 8 ## # Groups: ci [1] ## variable wkday hour default Mean Lower Upper ci ## &lt;fct&gt; &lt;ord&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 so2 Monday 0 01 January 1998 to 23 June 2… 2.93 2.63 3.19 0.95 ## 2 so2 Tuesday 0 01 January 1998 to 23 June 2… 3.21 3.02 3.46 0.95 ## 3 so2 Wednesday 0 01 January 1998 to 23 June 2… 3.35 3.09 3.59 0.95 ## 4 so2 Thursday 0 01 January 1998 to 23 June 2… 3.22 2.98 3.56 0.95 ## 5 so2 Friday 0 01 January 1998 to 23 June 2… 3.64 3.39 3.90 0.95 ## 6 so2 Saturday 0 01 January 1998 to 23 June 2… 4.25 4.01 4.58 0.95 All the numerical results are given by: myOutput$data$day.hour ## are the weekday and hour results myOutput$data$hour ## are the diurnal results myOutput$data$day ## are the weekday results myOutput$data$month ## are the monthly results It is also possible to plot the individual plots that make up the (four) plots produced by timeVariation: ## just the diurnal variation plot(myOutput, subset = &quot;hour&quot;) ## day and hour plot(myOutput, subset = &quot;day.hour&quot;) ## weekday variation plot(myOutput, subset = &quot;day&quot;) ## monthly variation plot(myOutput, subset = &quot;month&quot;) "],
["sec-calendarPlot.html", "Section 8 Calendar plots 8.1 Purpose 8.2 Calendar examples", " Section 8 Calendar plots 8.1 Purpose Sometimes it is useful to visualise data in a familiar way. Calendars are the obvious way to represent data for data on the time scale of days or months. The calendarPlot function provides an effective way to visualise data in this way by showing daily concentrations laid out in a calendar format. The concentration of a species is shown by its colour. The data can be shown in different ways. By default, calendarPlot overlays the day of the month. However, if wind speed and wind direction are available then an arrow can be shown for each day giving the vector-averaged wind direction. In addition, the arrow can be scaled according to the wind speed to highlight both the direction and strength of the wind on a particular day, which can help show the influence of meteorology on pollutant concentrations. calendarPlot can also show the daily mean concentration as a number on each day and can be extended to highlight those conditions where daily mean (or maximum etc.) concentrations are above a particular threshold. This approach is useful for highlighting daily air quality limits e.g. when the daily mean concentration is greater than 50 \\(\\mu\\)g m-3. The calendarPlot function can also be used to plot categorical scales. This is useful for plotting concentrations expressed as an air quality index i.e. intervals of concentrations that are expressed in ways like ‘very good’, ‘good’, ‘poor’ and so on. 8.2 Calendar examples The function is called in the usual way. As a minimum, a data frame, pollutant and year is required. So to show O3 concentrations for each day in 2003 (Figure 8.1). Note that if year is not supplied the full data set will be used. library(openair) calendarPlot(mydata, pollutant = &quot;o3&quot;, year = 2003) Figure 8.1: calendarPlot for O3 concentrations in 2003. It is sometimes useful to annotate the plots with other information. It is possible to show the daily mean wind angle, which can also be scaled to wind speed. The idea here being to provide some information on meteorological conditions on each day. Another useful option is to set annotate = \"value\" in which case the daily concentration will be shown on each day. Furthermore, it is sometimes useful to highlight particular values more clearly. For example, to highlight daily mean PM10 concentrations above 50 \\(\\mu\\)g m-3. This is where setting lim (a concentration limit) is useful. In setting lim the user can then differentiate the values below and above lim by colour of text, size of text and type of text e.g. plain and bold. Figure 8.2 highlights those days where PM10 concentrations exceed 50 \\(\\mu\\)g m-3 by making the annotation for those days bigger, bold and orange. Plotting the data in this way clearly shows the days where PM10 &gt; 50 \\(\\mu\\)g m-3. Other openair functions can be used to plot other statistics. For example, rollingMean could be used to calculate rolling 8-hour mean O3 concentrations. Then, calendarPlot could be used with statistic = \"max\" to show days where the maximum daily rolling 8-hour mean O3 concentration is greater than a certain threshold e.g. 100 or 120~\\(\\mu\\)g m-3. calendarPlot(mydata, pollutant = &quot;pm10&quot;, year = 2003, annotate = &quot;value&quot;, lim =50, cols = &quot;Purples&quot;, col.lim = c(&quot;black&quot;, &quot;orange&quot;), layout = c(4, 3)) Figure 8.2: calendarPlot for PM10 concentrations in 2003 with annotations highlighting those days where the concentration of PM10 &gt;50~\\(\\mu\\)g m-3. The numbers show the PM10 concentration in \\(\\mu\\)g m-3. To show wind angle, scaled to wind speed (Figure 8.3). calendarPlot(mydata, pollutant = &quot;o3&quot;, year = 2003, annotate = &quot;ws&quot;) Figure 8.3: calendarPlot for O3 concentrations in 2003 with annotations showing wind angle scaled to wind speed i.e. the longer the arrow, the higher the wind speed. It shows for example high O3 concentrations on the 17 and 18th of April were associated with strong north-easterly winds Note again that selectByDate can be useful. For example, to plot select months: calendarPlot(selectByDate(mydata, year = 2003, month = c(&quot;jun&quot;, &quot;jul&quot;, &quot;aug&quot;)), pollutant = &quot;o3&quot;, year = 2003) Figure 8.4 shows an example of plotting data with a categorical scale. In this case the options labels and breaks have been used to define concentration intervals and their descriptions. Note that breaks needs to be one longer than labels. In the example in Figure 8.4 the first interval (‘Very low’) is defined as concentrations from 0 to 50 (ppb), ‘Low’ is 50 to 100 and so on. Note that the upper value of breaks should be a number greater than the maximum value contained in the data to ensure that it is encompassed. In the example given in Figure 8.4 the maximum daily concentration is plotted. These types of plots are very useful for considering national or international air quality indexes. calendarPlot(mydata, pollutant = &quot;no2&quot;, year = 2003, breaks = c(0, 50, 100, 150, 1000), labels = c(&quot;Very low&quot;, &quot;Low&quot;, &quot;High&quot;, &quot;Very High&quot;), cols = &quot;increment&quot;, statistic = &quot;max&quot;) Figure 8.4: calendarPlot for NO2 concentrations in 2003 with a user-defined categorical scale. The user can explicitly set each colour interval: calendarPlot(mydata, pollutant = &quot;no2&quot;, year = 2003, breaks = c(0, 50, 100, 150, 1000), labels = c(&quot;Very low&quot;, &quot;Low&quot;, &quot;High&quot;, &quot;Very High&quot;), cols = c(&quot;lightblue&quot;, &quot;forestgreen&quot;, &quot;yellow&quot;, &quot;red&quot;), statistic = &quot;max&quot;) Note that in the case of categorical scales it is possible to define the breaks and labels first and then make the plot. For example: breaks &lt;- c(0, 34, 66, 100, 121, 141, 160, 188, 214, 240, 500) labels &lt;- c(&quot;Low.1&quot;, &quot;Low.2&quot;, &quot;Low.3&quot;, &quot;Moderate.4&quot;, &quot;Moderate.5&quot;, &quot;Moderate.6&quot;, &quot;High.7&quot;, &quot;High.8&quot;, &quot;High.9&quot;, &quot;Very High.10&quot;) calendarPlot(mydata, pollutant = &quot;no2&quot;, year = 2003, breaks = breaks, labels = labels, cols = &quot;jet&quot;, statistic = &quot;max&quot;) It is also possible to first use rollingMean to calculate statistics. For example, if one was interested in plotting the maximum daily rolling 8-hour mean concentration, the data could be prepared and plotted as follows. ## makes a new field &#39;rolling8o3&#39; dat &lt;- rollingMean(mydata, pollutant = &quot;o3&quot;, hours = 8) breaks &lt;- c(0, 34, 66, 100, 121, 141, 160, 188, 214, 240, 500) labels &lt;- c(&quot;Low.1&quot;, &quot;Low.2&quot;, &quot;Low.3&quot;, &quot;Moderate.4&quot;, &quot;Moderate.5&quot;, &quot;Moderate.6&quot;, &quot;High.7&quot;, &quot;High.8&quot;, &quot;High.9&quot;, &quot;Very High.10&quot;) calendarPlot(dat, pollutant = &quot;rolling8o3&quot;, year = 2003, breaks = breaks, labels = labels, cols = &quot;jet&quot;, statistic = &quot;max&quot;) The UK has an air quality index for O3, NO2, PM10 and described in detail at (http://uk-air.defra.gov.uk/air-pollution/daqi) and COMEAP (2011). The index is most relevant to air quality forecasting, but is used widely for public information. Most other countries have similar indexes. Note that the indexes are calculated for different averaging times dependent on the pollutant: rolling 8-hour mean for O3, hourly means for NO2 and a fixed 24-hour mean for PM10 and PM2.5. In the code below the labels and breaks are defined for each pollutant to make it easier to use the index in the calendarPlot function. ## the labels - same for all species labels &lt;- c(&quot;1 - Low&quot;, &quot;2 - Low&quot;, &quot;3 - Low&quot;, &quot;4 - Moderate&quot;, &quot;5 - Moderate&quot;, &quot;6 - Moderate&quot;, &quot;7 - High&quot;, &quot;8 - High&quot;, &quot;9 - High&quot;, &quot;10 - Very High&quot;) o3.breaks &lt;-c(0, 34, 66, 100, 121, 141, 160, 188, 214, 240, 500) no2.breaks &lt;- c(0, 67, 134, 200, 268, 335, 400, 468, 535, 600, 1000) pm10.breaks &lt;- c(0, 17, 34, 50, 59, 67, 75, 84, 92, 100, 1000) pm25.breaks &lt;- c(0, 12, 24, 35, 42, 47, 53, 59, 65, 70, 1000) Remember it is necessary to use the correct averaging time. Assuming data are imported using importAURN or similar, then the units will be in \\(\\mu\\)g m-3 — if not the user should ensure this is the case. Note that rather than showing the day of the month (the default), annotate = \"value\" can be used to show the actual numeric value on each day. In this way, the colours represent the categorical interval the concentration on a day corresponds to and the actual value itself is shown. ## import test data dat &lt;- importAURN(site = &quot;kc1&quot;, year = 2010) ## no2 index example calendarPlot(dat, year = 2010, pollutant = &quot;no2&quot;, labels = labels, breaks = no2.breaks, statistic = &quot;max&quot;, cols = &quot;jet&quot;) ## for PM10 or PM2.5 we need the daily mean concentration calendarPlot(dat, year = 2010, pollutant = &quot;pm10&quot;, labels = labels, breaks = pm10.breaks, statistic = &quot;mean&quot;, cols = &quot;jet&quot;) ## for ozone, need the rolling 8-hour mean dat &lt;- rollingMean(dat, pollutant = &quot;o3&quot;, hours = 8) calendarPlot(dat, year = 2010, pollutant = &quot;rolling8o3&quot;, labels = labels, breaks = o3.breaks, statistic = &quot;max&quot;, cols = &quot;jet&quot;) References "],
["sec-TheilSen.html", "Section 9 Theil-Sen trends 9.1 Trend estimates 9.2 Example trend analysis", " Section 9 Theil-Sen trends 9.1 Trend estimates Calculating trends for air pollutants is one of the most important and common tasks that can be undertaken. Trends are calculated for all sorts of reasons. Sometimes it is useful to have a general idea about how concentrations might have changed. On other occasions a more definitive analysis is required; for example, to establish statistically whether a trend is significant or not. The whole area of trend calculation is a complex one and frequently trends are calculated with little consideration as to their validity. Perhaps the most common approach is to apply linear regression and not think twice about it. However, there can be many pitfalls when using ordinary linear regression, such as the assumption of normality, autocorrelation etc. One commonly used approach for trend calculation in studies of air pollution is the non-parametric Mann-Kendall approach (Hirsch, Slack, and Smith 1982). Wilcox (2010) provides an excellent case for using ‘modern methods’ for regression including the benefits of non-parametric approaches and bootstrap simulations. Note also that the all the regression parameters are estimated through bootstrap resampling. The Theil-Sen method dates back to 1950, but the basic idea pre-dates 1950 (Theil 1950; Sen 1968). It is one of those methods that required the invention of fast computers to be practical. The basic idea is as follows. Given a set of \\(n\\) \\(x\\), \\(y\\) pairs, the slopes between all pairs of points are calculated. Note, the number of slopes can increase by \\(\\approx\\) \\(n^2\\) so that the number of slopes can increase rapidly as the length of the data set increases. The Theil-Sen estimate of the slope is the median of all these slopes. The advantage of the using the Theil-Sen estimator is that it tends to yield accurate confidence intervals even with non-normal data and heteroscedasticity (non-constant error variance). It is also resistant to outliers — both characteristics can be important in air pollution. As previously mentioned, the estimates of these parameters can be made more robust through bootstrap-resampling, which further adds to the computational burden, but is not an issue for most time series which are expressed either as monthly or annual means. Bootstrap resampling also provides the estimate of \\(p\\) for the slope. An issue that can be very important for time series is dependence or autocorrelation in the data. Normal (in the statistical sense) statistics assume that data are independent, but in time series this is rarely the case. The issue is that neighbouring data points are similar to one another (correlated) and therefore not independent. Ignoring this dependence would tend to give an overly optimistic impression of uncertainties. However, taking account of it is far from simple. A discussion of these issues is beyond the aims of this report and readers are referred to standard statistical texts on the issue. In openair we follow the suggestion of Kunsch (1989) of setting the block length to \\(n^{1/3}\\) where n is the length of the time series. There is a temptation when considering trends to use all the available data. Why? Often it is useful to consider specific periods. For example, is there any evidence that concentrations of have decreased since 2000? Clearly, the time period used depends on both the data and the questions, but it is good to be aware that considering subsets of data can be very insightful. Another aspect is that almost all trends are shown as mean concentration versus time; typically by year. Such analyses are very useful for understanding how concentrations have changed through time and for comparison with air quality limits and regulations. However, if one is interested in understanding why trends are as they are, it can be helpful to consider how concentrations vary in other ways. The trend functions in openair do just this. Trends can be plotted by day of the week, month, hour of the day, by wind direction sector and by different wind speed ranges. All these capabilities are easy to use and their effectiveness will depend on the situation in question. One of the reasons that trends are not considered in these many different ways is that there can be a considerable overhead in carrying out the analysis, which is avoided by using these functions. Few, for example, would consider a detailed trend analysis by hour of the day, ensuring that robust statistical methods were used and uncertainties calculated. However, it can be useful to consider how concentrations vary in this way. It may be, for example, that the hours around midday are dominated by heavy vehicle emissions rather than by cars — so is the trend for a pollutant different for those hours compared with say, hours dominated by other vehicle types? Similarly, a much more focussed trend analysis can be done by considering different wind direction, as this can help isolate different source influences. The TheilSen function is typically used to determine trends in pollutant concentrations over several years. However, it can be used to calculate the trend in any numeric variable. It calculates monthly mean values from daily, hourly or higher time resolution data, as well as working directly with monthly means. Whether it is meaningful to calculate trends over shorter periods of time (e.g. 2 years) depends very much on the data. It may well be that statistically significant trends can be detected over relatively short periods but it is another matter whether it matters. Because seasonal effects can be important for monthly data, there is the option to deseasonalise the data first. The timeVariation function are both useful to determine whether there is a seasonal cycle that should be removed. Note also that the symbols shown next to each trend estimate relate to how statistically significant the trend estimate is: \\(p\\) \\(&lt;\\) 0.001 = \\(\\ast\\ast\\ast\\), \\(p\\) \\(&lt;\\) 0.01 = \\(\\ast\\ast\\), \\(p\\) \\(&lt;\\) 0.05 = \\(\\ast\\) and \\(p\\) \\(&lt;\\) 0.1 = \\(+\\). 9.2 Example trend analysis We first show the use of the TheilSen function by applying it to concentrations of O3. The function is called as shown in Figure 9.1. library(openair) TheilSen(mydata, pollutant = &quot;o3&quot;, ylab = &quot;ozone (ppb)&quot;, deseason = TRUE, date.format = &quot;%Y&quot;) ## [1] &quot;Taking bootstrap samples. Please wait.&quot; Figure 9.1: Trends in ozone at Marylebone Road. The plot shows the deseasonalised monthly mean concentrations of O3. The solid red line shows the trend estimate and the dashed red lines show the 95% confidence intervals for the trend based on resampling methods. The overall trend is shown at the top-left as 0.38 (ppb) per year and the 95% confidence intervals in the slope from 0.21–0.51 ppb/year. The \\(\\ast\\ast\\ast\\) show that the trend is significant to the 0.001 level. Because the function runs simulations to estimate the uncertainty in the slope, it can take a little time for all the calculations to finish. These printed results show that in this case the trend in O3 was +0.38 units (i.e. ppb) per year as an average over the entire period. It also shows the 95% confidence intervals in the trend ranged between 0.21 to 0.51 ppb/year. Finally, the significance level in this case is very high; providing very strong evidence that concentrations of O3 increased over the period. The plot together with the summary results is shown in Figure 9.1. Note that if one wanted to display the confidence intervals in the slope at the 99% confidence intervals, the code would be Figure 9.2. TheilSen(mydata, pollutant = &quot;o3&quot;, ylab = &quot;ozone (ppb)&quot;, alpha = 0.01) Sometimes it is useful to consider a subset of data, perhaps by excluding some years. This is easy with the filter function. The following code calculates trends for years greater than 1999 i.e. from 2000 onward. TheilSen(filter(mydata, format(date, &quot;%Y&quot;) &gt; 1999), pollutant = &quot;o3&quot;, ylab = &quot;ozone (ppb)&quot;) It is also possible to calculate trends in many other ways e.g. by wind direction. Considering how trends vary by wind direction can be extremely useful because the influence of different sources invariably depends on the direction of the wind. The TheilSen function splits the wind direction into 8 sectors i.e. N, NE, E etc. The Theil-Sen slopes are then calculated for each direction in turn. This function takes rather longer to run because the simulations need to be run eight times in total. Considering concentrations of O3 again, the output is shown in Figure 9.2. Note that this plot is specifically laid out to assist interpretation, with each panel located at the correct point on the compass. This makes it easy to see immediately that there is essentially no trend in O3 for southerly winds i.e. where the road itself has the strongest influence. On the other hand the strongest evidence of increasing O3 are for northerly winds, where the influence of the road is much less. The reason that there is no trend in O3 for southerly winds is that there is always a great excess of NO, which reacts with O3 to form NO2. At this particular location it will probably take many more years before O3 concentrations start to increase when the wind direction is southerly. Nevertheless, there will always be some hours that do not have such high concentrations of NO. TheilSen(mydata, pollutant = &quot;o3&quot;, type = &quot;wd&quot;, deseason = TRUE, date.format = &quot;%Y&quot;, ylab = &quot;ozone (ppb)&quot;) ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; Figure 9.2: Trends in ozone at Marylebone Road split by eight wind sectors. The TheilSen function will automatically organise the separate panels by the different compass directions. The option slope.percent can be set to express slope estimates as a percentage change per year. This is useful for comparing slopes for sites with very different concentration levels and for comparison with emission inventories. The percentage change uses the concentration at the beginning and end months to express the mean slope. The trend, \\(T\\) is defined as: \\[ T [\\%.yr^{-1}] = 100.\\left(\\frac{C_{End}}{C_{Start}} - 1\\right)\\Bigg /N_{years} \\tag{9.1} \\] where \\(C_{End}\\) and \\(C_{Start}\\) are the mean concentrations for the end and start date, respectfully. \\(N_{years}\\) is the number of years (or fractions of) the time series spans. TheilSen(mydata, pollutant = &quot;o3&quot;, deseason = TRUE, slope.percent = TRUE) The TheilSen function was written to work with hourly data, which is then averaged into monthly or annual data. However, it is realised that users may already have data that is monthly or annual. The function can therefore accept as input monthly or annual data directly. However, it is necessary to ensure the date field is in the correct format. Assuming data in an Excel file in the format dd/mm/YYYY (e.g. 23/11/2008), it is necessary to convert this to a date format understood by R, as shown below. Similarly, if annual data were available, get the dates in formats like ‘2005-01-01’, ‘2006-01-01’ … and make sure the date is again formatted using as.Date. Note that if dates are pre-formatted as YYYY-mm-dd, then it is sufficient to use as.Date without providing any format information because it is already in the correct format. mydata$date = as.Date(mydata$date, format = &quot;%d/%m/%Y&quot;) Finally, the TheilSen function can consider trends at different sites, provided the input data are correctly formatted. For input, a data frame with three columns is required: date, pollutant and site. The call would then be, for example: TheilSen(mydata, pollutant = &quot;no2&quot;, type = &quot;site&quot;) 9.2.1 Output The TheilSen function provides lots of output data for further analysis or adding to a report. To obtain it, it is necessary to read it into a variable: MKresults &lt;- TheilSen(mydata, pollutant = &quot;o3&quot;, deseason = TRUE, type = &quot;wd&quot;) ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; ## [1] &quot;Taking bootstrap samples. Please wait.&quot; This returns a list of two data frames containing all the monthly mean values and trend statistics and an aggregated summary. The first 6 lines are shown next: head(MKresults$data[[1]]) ## wd date conc a b upper.a upper.b lower.a ## 1 E 1998-01-01 5.552253 -2.825001 0.0007185124 -8.826666 0.001230109 3.848278 ## 2 E 1998-02-01 2.919639 -2.825001 0.0007185124 -8.826666 0.001230109 3.848278 ## 3 E 1998-03-01 3.849363 -2.825001 0.0007185124 -8.826666 0.001230109 3.848278 ## 4 E 1998-04-01 4.051668 -2.825001 0.0007185124 -8.826666 0.001230109 3.848278 ## 5 E 1998-05-01 2.304686 -2.825001 0.0007185124 -8.826666 0.001230109 3.848278 ## 6 E 1998-06-01 -1.560438 -2.825001 0.0007185124 -8.826666 0.001230109 3.848278 ## lower.b p p.stars slope intercept intercept.lower ## 1 0.0001449688 0.01669449 * 0.262257 -2.825001 3.848278 ## 2 0.0001449688 0.01669449 * 0.262257 -2.825001 3.848278 ## 3 0.0001449688 0.01669449 * 0.262257 -2.825001 3.848278 ## 4 0.0001449688 0.01669449 * 0.262257 -2.825001 3.848278 ## 5 0.0001449688 0.01669449 * 0.262257 -2.825001 3.848278 ## 6 0.0001449688 0.01669449 * 0.262257 -2.825001 3.848278 ## intercept.upper lower upper slope.percent lower.percent ## 1 -8.826666 0.05291362 0.4489896 5.79801 0.9925881 ## 2 -8.826666 0.05291362 0.4489896 5.79801 0.9925881 ## 3 -8.826666 0.05291362 0.4489896 5.79801 0.9925881 ## 4 -8.826666 0.05291362 0.4489896 5.79801 0.9925881 ## 5 -8.826666 0.05291362 0.4489896 5.79801 0.9925881 ## 6 -8.826666 0.05291362 0.4489896 5.79801 0.9925881 ## upper.percent ## 1 11.9614 ## 2 11.9614 ## 3 11.9614 ## 4 11.9614 ## 5 11.9614 ## 6 11.9614 Often only the trend statistics are required and not all the monthly values. These can be obtained by: MKresults$data[[2]] ## wd p.stars date conc a b upper.a ## 1 E * 2001-09-15 5.989974 -2.825001 7.185124e-04 -8.8266663 ## 2 N *** 2001-09-15 9.786267 -19.142102 2.485907e-03 -28.7157702 ## 3 NE *** 2001-09-15 9.728994 -9.728741 1.624970e-03 -24.8702270 ## 4 NW *** 2001-09-15 9.786755 -12.940875 1.937119e-03 -22.4192235 ## 5 S 2001-09-15 5.052728 4.472516 2.509968e-05 1.0744367 ## 6 SE 2001-09-15 5.780645 4.822713 7.357549e-05 0.8230425 ## 7 SW 2001-09-15 4.761100 1.818359 2.444766e-04 -1.9192744 ## 8 W ** 2001-09-15 5.618727 -1.178793 5.736058e-04 -5.6090971 ## upper.b lower.a lower.b p slope intercept ## 1 0.0012301086 3.848278 1.449688e-04 0.016694491 0.262257022 -2.825001 ## 2 0.0032893251 -9.725509 1.649012e-03 0.000000000 0.907355964 -19.142102 ## 3 0.0029640572 3.185458 5.003924e-04 0.000000000 0.593114074 -9.728741 ## 4 0.0027690442 -3.396506 1.122414e-03 0.000000000 0.707048447 -12.940875 ## 5 0.0003281521 7.156572 -2.081018e-04 0.868113523 0.009161382 4.472516 ## 6 0.0004318379 8.727162 -2.572925e-04 0.684474124 0.026855053 4.822713 ## 7 0.0005716588 5.538235 -8.999974e-05 0.110183639 0.089233973 1.818359 ## 8 0.0009552189 3.041723 2.044787e-04 0.003338898 0.209366110 -1.178793 ## intercept.lower intercept.upper lower upper slope.percent ## 1 3.848278 -8.8266663 0.05291362 0.4489896 5.7980099 ## 2 -9.725509 -28.7157702 0.60188926 1.2006037 14.4454302 ## 3 3.185458 -24.8702270 0.18264323 1.0818809 8.6085473 ## 4 -3.396506 -22.4192235 0.40968128 1.0107011 10.2917646 ## 5 7.156572 1.0744367 -0.07595715 0.1197755 0.1937191 ## 6 8.727162 0.8230425 -0.09391177 0.1576208 0.4816904 ## 7 5.538235 -1.9192744 -0.03284991 0.2086555 2.0662607 ## 8 3.041723 -5.6090971 0.07463472 0.3486549 4.4665024 ## lower.percent upper.percent ## 1 0.9925881 11.961401 ## 2 8.4310805 24.381910 ## 3 2.1997335 19.875875 ## 4 5.0687904 17.131133 ## 5 -1.5105886 2.703463 ## 6 -1.5405900 3.008348 ## 7 -0.7113745 5.313247 ## 8 1.4540385 8.381275 In the results above the lower and upper fields provide the 95% (or chosen confidence interval using the alpha option) of the trend and slope is the trend estimate expressed in units/year. Applequist, Scott. 2012. “Wind Rose Bias Correction.” Journal of Applied Meteorology and Climatology 51 (7): 1305–9. Ashbaugh, Lowell L., William C. Malm, and Willy Z. Sadeh. 1985. “A residence time probability analysis of sulfur concentrations at grand Canyon National Park.” Atmospheric Environment (1967) 19 (8): 1263–70. https://doi.org/10.1016/0004-6981(85)90256-2. Carslaw, D. C., and S. D. Beevers. 2013. “Characterising and Understanding Emission Sources Using Bivariate Polar Plots and K-Means Clustering.” Environmental Modelling &amp; Software 40 (0): 325–29. https://doi.org/10.1016/j.envsoft.2012.09.005. Carslaw, D. C., S. D. Beevers, K. Ropkins, and M. C. Bell. 2006. “Detecting and Quantifying Aircraft and Other on-Airport Contributions to Ambient Nitrogen Oxides in the Vicinity of a Large International Airport.” Atmospheric Environment 40 (28): 5424–34. COMEAP. 2011. “Review of the Uk Air Quality Index: A Report by the Committee on the Medical Effects of Air Pollutants.” http://comeap.org.uk/documents/reports/130-review-of-the-uk-air-quality-index.html. Droppo, James G, and Bruce A Napier. 2008. “Wind Direction Bias in Generating Wind Roses and Conducting Sector-Based Air Dispersion Modeling.” Journal of the Air &amp; Waste Management Association 58 (7): 913–18. Grange, Stuart K, Alastair C Lewis, and David C Carslaw. 2016. “Source Apportionment Advances Using Polar Plots of Bivariate Correlation and Regression Statistics.” Atmospheric Environment 145: 128–34. Hastie, T. J., and R. J. Tibshirani. 1990. Generalized Additive Models. London: Chapman; Hall. Henry, Ronald, Gary A. Norris, Ram Vedantham, and Jay R. Turner. 2009. “Source Region Identification Using Kernel Smoothing.” Article. Environmental Science &amp; Technology 43 (11): 4090–7. https://doi.org/{10.1021/es8011723}. Hirsch, R. M., J. R. Slack, and R. A. Smith. 1982. “Techniques of Trend Analysis for Monthly Water-Quality Data.” Water Resources Research 18 (1): 107–21. Kunsch, H. R. 1989. “The Jackknife and the Bootstrap for General Stationary Observations.” Annals of Statistics 17 (3): 1217–41. Sen, P. K. 1968. “Estimates of Regression Coefficient Based on Kendall’s Tau.” Journal of the American Statistical Association 63(324): 1379–89. Theil, H. 1950. “A Rank Invariant Method of Linear and Polynomial Regression Analysis, I, Ii, Iii.” Proceedings of the Koninklijke Nederlandse Akademie Wetenschappen, Series A – Mathematical Sciences 53: 386–92, 521–25, 1397–1412. Uria-Tellaetxe, I, and D. C. Carslaw. 2014. “Conditional Bivariate Probability Function for Source Identification.” Environmental Modelling &amp; Software 59: 1–9. https://doi.org/10.1016/j.envsoft.2014.05.002. Westmoreland, E. J., N Carslaw, D. C. Carslaw, A. Gillah, and E. Bates. 2007. “Analysis of Air Quality Within a Street Canyon Using Statistical and Dispersion Modelling Techniques.” Atmospheric Environment 41 (39): 9195–9205. Wilcox, Rand R. 2010. Fundamentals of Modern Statistical Methods: Substantially Improving Power and Accuracy. 2nd ed. Springer New York. http://www.springerlink.com/content/978-1-4419-5524-1. Wood, S. N. 2006. Generalized Additive Models: An Introduction with R. Chapman; Hall/CRC. Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/. ———. 2020. Bookdown: Authoring Books and Technical Documents with R Markdown. https://CRAN.R-project.org/package=bookdown. Yu, K. N., Y. P. Cheung, T. Cheung, and R. C. Henry. 2004. “Identifying the Impact of Large Urban Airports on Local Air Quality by Nonparametric Regression.” Atmospheric Environment 38 (27): 4501–7. References "]
]
